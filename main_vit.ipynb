{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6efdca0a-769d-4cbb-a461-28d5579f8c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "#IMPORTS\n",
    "import cv2\n",
    "import numpy as np \n",
    "import os\n",
    "from pytesseract import Output\n",
    "import pytesseract\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "import PIL.Image as Image\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torch import nn\n",
    "#Proceed to EOF to use the grading function, run all functions sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75620ab6-a866-483e-bd0c-4a8f7bd51dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ea4636b-797c-4b5e-b451-2a88415d51fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\tusha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the word list\n",
    "nltk.download('words')\n",
    "# Get the list of valid words\n",
    "valid_words = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0124aeed-5a3f-4b22-b77b-5fab92432646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_gibberish(text, threshold=0.45):\n",
    "    words_in_text = text.split()\n",
    "    if not words_in_text:\n",
    "        return True\n",
    "    \n",
    "    valid_count = sum(1 for word in words_in_text if word.lower() in valid_words)\n",
    "    valid_ratio = valid_count / len(words_in_text)\n",
    "\n",
    "    \n",
    "    return valid_ratio < threshold\n",
    "\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "\n",
    "    # Calculate the rotation matrix\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    \n",
    "    # Calculate the sine and cosine of the rotation matrix\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "\n",
    "    # Compute the new bounding dimensions of the image\n",
    "    new_w = int((h * sin) + (w * cos))\n",
    "    new_h = int((h * cos) + (w * sin))\n",
    "\n",
    "    # Adjust the rotation matrix to account for translation\n",
    "    M[0, 2] += (new_w / 2) - center[0]\n",
    "    M[1, 2] += (new_h / 2) - center[1]\n",
    "\n",
    "    # Perform the actual rotation and return the image\n",
    "    rotated = cv2.warpAffine(image, M, (new_w, new_h))\n",
    "    return rotated\n",
    "\n",
    "\n",
    "def correct_orientation(image):\n",
    "    h, w = image.shape[:2]\n",
    "    new_image = image.copy()\n",
    "    if (h<w) :\n",
    "        new_image = rotate_image(image, 90)\n",
    "    text = pytesseract.image_to_string(new_image)\n",
    "    if is_gibberish(text):\n",
    "        new_image = rotate_image(new_image, 180)\n",
    "        \n",
    "    return new_image\n",
    "    \n",
    "\n",
    "def resizeImg(img, scale = 0.1): \n",
    "    width = int(img.shape[1]*scale)\n",
    "    height = int(img.shape[0]*(scale))\n",
    "    dimensions = (width,height)\n",
    "    return cv2.resize(img,dimensions,interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def compressImages(directory):\n",
    "    filenames = os.listdir(directory)\n",
    "    for image in filenames:\n",
    "        img = cv2.imread(f'{directory}/{image}')  \n",
    "        scale = round(900/max(img.shape[:2]), 2)\n",
    "        img_reshape = resizeImg(img, scale)\n",
    "        img_gray = cv2.cvtColor(img_reshape,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        img_orn = correct_orientation(img_gray)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(1,1))\n",
    "        sharpened_image = cv2.filter2D(img_orn, -1, kernel)\n",
    "        if not os.path.exists(\"compressed\"):\n",
    "              os.makedirs(\"compressed\")\n",
    "        \n",
    "        cv2.imwrite(f\"compressed/{image}\",sharpened_image)\n",
    "    print(\"Done\")\n",
    "\n",
    "def compressImg(img):\n",
    "    scale = round(900/max(img.shape[:2]), 2)\n",
    "    img_reshape = resizeImg(img, scale)\n",
    "    img_gray = cv2.cvtColor(img_reshape,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    img_orn = correct_orientation(img_gray)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(1,1))\n",
    "    sharpened_image = cv2.filter2D(img_orn, -1, kernel)\n",
    "\n",
    "    return sharpened_image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f30b245b-d64f-4ece-b6af-e7a4be9cf6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tf_answers(img, qno = -1):\n",
    "    \n",
    "    try:\n",
    "        img  = compressImg(img)\n",
    "        img = (img[:, 3*img.shape[1]//5:])\n",
    "        H,W = img.shape[0], img.shape[1]\n",
    "    \n",
    "        #print(img.shape)\n",
    "        #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #Image.fromarray(gray).show()\n",
    "        canny = cv2.Canny(img, 50, 200, None, 3)\n",
    "        #Image.fromarray(canny).show()\n",
    "        \n",
    "        try:\n",
    "            lines = cv2.HoughLines(canny, 1, np.pi/180, 200)\n",
    "            lines = np.reshape(lines, (lines.shape[0], 2))\n",
    "        \n",
    "            \n",
    "            vertical_lines = []\n",
    "            \n",
    "            for  i in lines:\n",
    "                if abs(np.cos(i[1]))>0.99:\n",
    "                    if(np.cos(i[1])<0):\n",
    "                        i[0] = abs(i[0])\n",
    "                        i[1] = np.pi + i[1]\n",
    "                        vertical_lines.append(i)\n",
    "                    else:\n",
    "                        vertical_lines.append(i)\n",
    "                        \n",
    "            vertical_lines = np.array(vertical_lines)\n",
    "            vertical_lines = vertical_lines[vertical_lines[:, 0].argsort()]\n",
    "            v_edges = [vertical_lines[0],]\n",
    "            \n",
    "            for i in range(1,len(vertical_lines)):\n",
    "                if abs(vertical_lines[i][0] - v_edges[len(v_edges)-1][0]) < W//3: #Magic number\n",
    "                    pass\n",
    "                else:\n",
    "                    v_edges.append(vertical_lines[i])\n",
    "        \n",
    "            v_edges = np.array(v_edges, dtype = int)\n",
    "            \n",
    "    \n",
    "        \n",
    "            TFcol = img[:, v_edges[0][0]:v_edges[1][0]]  #Image of the True/False Column\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"ERROR\")\n",
    "            return None\n",
    "\n",
    "        \n",
    "        #Image.fromarray(TFcol).show()    \n",
    "        cannyTF = cv2.Canny(TFcol, 10, 100, None, 3) \n",
    "    \n",
    "        boxTF = cannyTF.copy()  # To show locations of True/False boxes after processing canny image of True/False Column Image\n",
    "        horizontal = []         # Tracks the horizontal lines\n",
    "        kernel = 5              # Determines sensitivity in Line detection, ( 3 - 7) is the ideal range\n",
    "        tolerance = 10\n",
    "        for i in range(kernel,cannyTF.shape[0]-kernel):\n",
    "            h_line = False\n",
    "            for j in range(tolerance, cannyTF.shape[1]-tolerance):\n",
    "                for k in range(-1*kernel, kernel):\n",
    "                    if (cannyTF[i+k][j-1] == 255 or cannyTF[i+k][j] == 255 or cannyTF[i+k][j+1] == 255):\n",
    "                        h_line = True\n",
    "                        break\n",
    "                else:\n",
    "                    h_line = False\n",
    "                    break\n",
    "                \n",
    "                h_line = True\n",
    "            if (h_line):\n",
    "                horizontal.append(i)\n",
    "                boxTF[i,:] = 0\n",
    "            else:\n",
    "                boxTF[i, :] = 255\n",
    "        \n",
    "        min_lines = []                       # Stores the row of 1 line from each horizontal lines cluster, \n",
    "        s, n = 0, 0\n",
    "        \n",
    "        for i in range(len(horizontal)-1):\n",
    "            if horizontal[i+1]-horizontal[i] <= kernel:\n",
    "                s += horizontal[i]\n",
    "                n += 1\n",
    "                if( i == len(horizontal)-2):\n",
    "                    min_lines.append(int(s/n))\n",
    "    \n",
    "            else:\n",
    "                s += horizontal[i]\n",
    "                n += 1\n",
    "                min_lines.append(int(s/n))\n",
    "                if( i == len(horizontal)-2):\n",
    "                    min_lines.append(horizontal[-1])\n",
    "                s = 0\n",
    "                n = 0\n",
    "                \n",
    "        #print(horizontal)\n",
    "    \n",
    "        #Removes if a line is detected at the top of the Image\n",
    "        try:\n",
    "            n = len(min_lines)\n",
    "            s = 0\n",
    "            diff = []\n",
    "            for i in range(0, n-1):\n",
    "               diff.append(min_lines[i+1]-min_lines[i])\n",
    "            diff = np.array(diff)\n",
    "            mean_diff = np.mean(diff)\n",
    "            std_diff = np.std(diff)\n",
    "            ini_dist = 0\n",
    "            #print(mean_diff, std_diff, min_lines)\n",
    "                \n",
    "            if min_lines[0] < 10:\n",
    "                min_lines = min_lines[1:]\n",
    "            if (qno < 0):\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    min_lines = min_lines[:qno+1]\n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"ERROR B\") \n",
    "    \n",
    "        splits = 0\n",
    "        splitted_images = []\n",
    "        img_height = 224\n",
    "        img_width = 224\n",
    "        for i in range(len(min_lines)-1):\n",
    "            sliced_img = TFcol[min_lines[i]:min_lines[i+1], :]\n",
    "            \n",
    "            if (sliced_img.shape[0] < 25 or sliced_img.shape[0]>200):\n",
    "                continue\n",
    "            resized_img = cv2.resize(sliced_img, (img_width, img_height))\n",
    "            # _, binary_img = cv2.threshold(resized_img, 128, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            # rescaled_img = binary_img / 255.0\n",
    "            splitted_images.append(resized_img)\n",
    "            splits += 1\n",
    "        #print(\"splits \", splits)\n",
    "        splitted_images = np.array(splitted_images)\n",
    "        return splitted_images \n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d56dee3c-95fd-4f38-acf8-599f137e98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answers(model, images, correct_answers, device):\n",
    "    # Define a map from class indices to labels\n",
    "    prediction_map = {2: 'True', 1: 'False', 0: 'Empty'}\n",
    "\n",
    "    pretrained_vit_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "        transforms.Lambda(lambda img: img.convert(\"RGB\")),  # Convert grayscale images to RGB\n",
    "        transforms.ToTensor(),  # Convert to tensor\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Normalize\n",
    "    ])\n",
    "    \n",
    "    # Transform images and prepare for prediction\n",
    "    transformed_images = [pretrained_vit_transforms(Image.fromarray((image).astype(np.uint8))) for image in images]\n",
    "    transformed_images = torch.stack(transformed_images).to(device)\n",
    "    \n",
    "    # Predict the output for each image using the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(transformed_images)\n",
    "    \n",
    "    # Convert predictions to readable format\n",
    "    _, predicted_indices = torch.max(outputs, 1)\n",
    "    predicted_answers = [prediction_map[idx.item()] for idx in predicted_indices]\n",
    "    \n",
    "    # Calculate marks\n",
    "    marks = []\n",
    "    for pred, correct in zip(predicted_answers, correct_answers):\n",
    "        if pred == correct:\n",
    "            marks.append(1)\n",
    "        else:\n",
    "            marks.append(0)\n",
    "    \n",
    "    return marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be0ef05c-ee34-438b-98ad-c2d8088d8057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grade_Sheets(directory, model, correct_answers, qno=-1):\n",
    "    with open(\"Graded_Sheets_vit.csv\", \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"ID\", \"Predicted Marks\"])\n",
    "        \n",
    "        files = [file for file in os.listdir(directory) if file.endswith(('jpg', 'jpeg', 'png'))]\n",
    "        \n",
    "        for file in tqdm(files, desc=\"Grading Sheets\"):\n",
    "            img = cv2.imread(f\"{directory}/{file}\")\n",
    "            images = save_tf_answers(img, qno)\n",
    "            \n",
    "            if images is None:\n",
    "                continue  # Skip if no images were extracted\n",
    "            \n",
    "            marks = evaluate_answers(model, images, correct_answers, device)\n",
    "            \n",
    "            writer.writerow([file, np.sum(marks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb62ef79-1b54-4289-b3f2-80058ea485ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grading Sheets: 100%|██████████████████████████████████████████████████████████████████| 48/48 [04:31<00:00,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED: 271.22452449798584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#USAGE => Add the directory path to the sheets to be graded in directory variable, load model, load correct answers.\n",
    "\n",
    "directory = \"C:/Users/tusha/Desktop/NCVP/Data Samples/Sample_Data\"\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_save_path = \"best_models/pretrained_vit_0.9575.pth\"\n",
    "\n",
    "# Load the model architecture\n",
    "pretrained_vit = torchvision.models.vit_b_16(weights=None).to(device)  # Initialize with no weights\n",
    "pretrained_vit.heads = nn.Linear(in_features=768, out_features=3).to(device)  # Assuming 3 classes: True, False, Empty\n",
    "\n",
    "# Load the saved state dictionary into the model\n",
    "pretrained_vit.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "pretrained_vit.eval()\n",
    "\n",
    "#correct_answers = ['True', 'True', 'False', 'False', 'True', 'False', 'True', 'False', 'False', 'True']\n",
    "correct_answers = ['False', 'False', 'False', 'False', 'False', 'False', 'True', 'True', 'True', 'True']\n",
    "\n",
    "\n",
    "s = time.time()\n",
    "Grade_Sheets(directory, pretrained_vit, correct_answers)\n",
    "print(\"FINISHED:\", time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9c475-234c-4fae-8765-bdfc671c0f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
