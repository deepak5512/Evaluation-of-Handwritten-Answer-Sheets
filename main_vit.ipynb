{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6efdca0a-769d-4cbb-a461-28d5579f8c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "#IMPORTS\n",
    "import cv2\n",
    "import numpy as np \n",
    "import os\n",
    "from pytesseract import Output\n",
    "import pytesseract\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "import PIL.Image as Image\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import shutil\n",
    "#Proceed to EOF to use the grading function, run all functions sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75620ab6-a866-483e-bd0c-4a8f7bd51dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ea4636b-797c-4b5e-b451-2a88415d51fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\tusha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the word list\n",
    "nltk.download('words')\n",
    "# Get the list of valid words\n",
    "valid_words = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0124aeed-5a3f-4b22-b77b-5fab92432646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_gibberish(text, threshold=0.40):\n",
    "    words_in_text = text.split()\n",
    "    if not words_in_text:\n",
    "        return True\n",
    "    \n",
    "    valid_count = sum(1 for word in words_in_text if word.lower() in valid_words)\n",
    "    valid_ratio = valid_count / len(words_in_text)\n",
    "\n",
    "    \n",
    "    return valid_ratio < threshold\n",
    "\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "\n",
    "    # Calculate the rotation matrix\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    \n",
    "    # Calculate the sine and cosine of the rotation matrix\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "\n",
    "    # Compute the new bounding dimensions of the image\n",
    "    new_w = int((h * sin) + (w * cos))\n",
    "    new_h = int((h * cos) + (w * sin))\n",
    "\n",
    "    # Adjust the rotation matrix to account for translation\n",
    "    M[0, 2] += (new_w / 2) - center[0]\n",
    "    M[1, 2] += (new_h / 2) - center[1]\n",
    "\n",
    "    # Perform the actual rotation and return the image\n",
    "    rotated = cv2.warpAffine(image, M, (new_w, new_h))\n",
    "    return rotated\n",
    "\n",
    "\n",
    "def correct_orientation(image):\n",
    "    h, w = image.shape[:2]\n",
    "    new_image = image.copy()\n",
    "    if (h<w) :\n",
    "        new_image = rotate_image(image, 90)\n",
    "    text = pytesseract.image_to_string(new_image)\n",
    "    if is_gibberish(text):\n",
    "        new_image = rotate_image(new_image, 180)\n",
    "        \n",
    "    return new_image\n",
    "    \n",
    "\n",
    "def resizeImg(img, scale = 0.1): \n",
    "    width = int(img.shape[1]*scale)\n",
    "    height = int(img.shape[0]*(scale))\n",
    "    dimensions = (width,height)\n",
    "    return cv2.resize(img,dimensions,interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def compressImages(directory):\n",
    "    filenames = os.listdir(directory)\n",
    "    for image in filenames:\n",
    "        img = cv2.imread(f'{directory}/{image}')  \n",
    "        scale = round(900/max(img.shape[:2]), 2)\n",
    "        img_reshape = resizeImg(img, scale)\n",
    "        img_gray = cv2.cvtColor(img_reshape,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        img_orn = correct_orientation(img_gray)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(1,1))\n",
    "        sharpened_image = cv2.filter2D(img_orn, -1, kernel)\n",
    "        if not os.path.exists(\"compressed\"):\n",
    "              os.makedirs(\"compressed\")\n",
    "        \n",
    "        cv2.imwrite(f\"compressed/{image}\",sharpened_image)\n",
    "    print(\"Done\")\n",
    "\n",
    "def compressImg(img):\n",
    "    scale = round(900/max(img.shape[:2]), 2)\n",
    "    img_reshape = resizeImg(img, scale)\n",
    "    img_gray = cv2.cvtColor(img_reshape,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    img_orn = correct_orientation(img_gray)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(1,1))\n",
    "    sharpened_image = cv2.filter2D(img_orn, -1, kernel)\n",
    "\n",
    "    return sharpened_image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f30b245b-d64f-4ece-b6af-e7a4be9cf6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tf_answers(img, qno = -1):\n",
    "    \n",
    "    try:\n",
    "        img  = compressImg(img)\n",
    "        img = (img[:, 3*img.shape[1]//5:])\n",
    "        H,W = img.shape[0], img.shape[1]\n",
    "    \n",
    "        #print(img.shape)\n",
    "        #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #Image.fromarray(gray).show()\n",
    "        canny = cv2.Canny(img, 50, 200, None, 3)\n",
    "        #Image.fromarray(canny).show()\n",
    "        \n",
    "        try:\n",
    "            lines = cv2.HoughLines(canny, 1, np.pi/180, 200)\n",
    "            lines = np.reshape(lines, (lines.shape[0], 2))\n",
    "        \n",
    "            \n",
    "            vertical_lines = []\n",
    "            \n",
    "            for  i in lines:\n",
    "                if abs(np.cos(i[1]))>0.99:\n",
    "                    if(np.cos(i[1])<0):\n",
    "                        i[0] = abs(i[0])\n",
    "                        i[1] = np.pi + i[1]\n",
    "                        vertical_lines.append(i)\n",
    "                    else:\n",
    "                        vertical_lines.append(i)\n",
    "                        \n",
    "            vertical_lines = np.array(vertical_lines)\n",
    "            vertical_lines = vertical_lines[vertical_lines[:, 0].argsort()]\n",
    "            v_edges = [vertical_lines[0],]\n",
    "            \n",
    "            for i in range(1,len(vertical_lines)):\n",
    "                if abs(vertical_lines[i][0] - v_edges[len(v_edges)-1][0]) < W//3: #Magic number\n",
    "                    pass\n",
    "                else:\n",
    "                    v_edges.append(vertical_lines[i])\n",
    "        \n",
    "            v_edges = np.array(v_edges, dtype = int)\n",
    "            \n",
    "    \n",
    "        \n",
    "            TFcol = img[:, v_edges[0][0]:v_edges[1][0]]  #Image of the True/False Column\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"ERROR\")\n",
    "            return None\n",
    "\n",
    "        \n",
    "        #Image.fromarray(TFcol).show()    \n",
    "        cannyTF = cv2.Canny(TFcol, 10, 100, None, 3) \n",
    "    \n",
    "        boxTF = cannyTF.copy()  # To show locations of True/False boxes after processing canny image of True/False Column Image\n",
    "        horizontal = []         # Tracks the horizontal lines\n",
    "        kernel = 5              # Determines sensitivity in Line detection, ( 3 - 7) is the ideal range\n",
    "        tolerance = 10\n",
    "        for i in range(kernel,cannyTF.shape[0]-kernel):\n",
    "            h_line = False\n",
    "            for j in range(tolerance, cannyTF.shape[1]-tolerance):\n",
    "                for k in range(-1*kernel, kernel):\n",
    "                    if (cannyTF[i+k][j-1] == 255 or cannyTF[i+k][j] == 255 or cannyTF[i+k][j+1] == 255):\n",
    "                        h_line = True\n",
    "                        break\n",
    "                else:\n",
    "                    h_line = False\n",
    "                    break\n",
    "                \n",
    "                h_line = True\n",
    "            if (h_line):\n",
    "                horizontal.append(i)\n",
    "                boxTF[i,:] = 0\n",
    "            else:\n",
    "                boxTF[i, :] = 255\n",
    "        \n",
    "        min_lines = []                       # Stores the row of 1 line from each horizontal lines cluster, \n",
    "        s, n = 0, 0\n",
    "        \n",
    "        for i in range(len(horizontal)-1):\n",
    "            if horizontal[i+1]-horizontal[i] <= kernel:\n",
    "                s += horizontal[i]\n",
    "                n += 1\n",
    "                if( i == len(horizontal)-2):\n",
    "                    min_lines.append(int(s/n))\n",
    "    \n",
    "            else:\n",
    "                s += horizontal[i]\n",
    "                n += 1\n",
    "                min_lines.append(int(s/n))\n",
    "                if( i == len(horizontal)-2):\n",
    "                    min_lines.append(horizontal[-1])\n",
    "                s = 0\n",
    "                n = 0\n",
    "                \n",
    "        #print(horizontal)\n",
    "    \n",
    "        #Removes if a line is detected at the top of the Image\n",
    "        try:\n",
    "            n = len(min_lines)\n",
    "            s = 0\n",
    "            diff = []\n",
    "            for i in range(0, n-1):\n",
    "               diff.append(min_lines[i+1]-min_lines[i])\n",
    "            diff = np.array(diff)\n",
    "            mean_diff = np.mean(diff)\n",
    "            std_diff = np.std(diff)\n",
    "            ini_dist = 0\n",
    "            #print(mean_diff, std_diff, min_lines)\n",
    "                \n",
    "            if min_lines[0] < 10:\n",
    "                min_lines = min_lines[1:]\n",
    "            if (qno < 0):\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    min_lines = min_lines[:qno+1]\n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "            if(len(min_lines >=13):\n",
    "                min_lines = min_lines[2:]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"ERROR B\") \n",
    "    \n",
    "        splits = 0\n",
    "        splitted_images = []\n",
    "        img_height = 224\n",
    "        img_width = 224\n",
    "        for i in range(len(min_lines)-1):\n",
    "            sliced_img = TFcol[min_lines[i]:min_lines[i+1], :]\n",
    "            \n",
    "            if (sliced_img.shape[0] < 25 or sliced_img.shape[0]>200):\n",
    "                continue\n",
    "            resized_img = cv2.resize(sliced_img, (img_width, img_height))\n",
    "            # _, binary_img = cv2.threshold(resized_img, 128, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            # rescaled_img = binary_img / 255.0\n",
    "            splitted_images.append(resized_img)\n",
    "            splits += 1\n",
    "        #print(\"splits \", splits)\n",
    "        splitted_images = np.array(splitted_images)\n",
    "        return splitted_images \n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d56dee3c-95fd-4f38-acf8-599f137e98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answers(model, images, correct_answers, device):\n",
    "    # Define a map from class indices to labels\n",
    "    prediction_map = {2: 'True', 1: 'False', 0: 'Empty'}\n",
    "\n",
    "    pretrained_vit_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "        transforms.Lambda(lambda img: img.convert(\"RGB\")),  # Convert grayscale images to RGB\n",
    "        transforms.ToTensor(),  # Convert to tensor\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Normalize\n",
    "    ])\n",
    "    \n",
    "    # Transform images and prepare for prediction\n",
    "    transformed_images = [pretrained_vit_transforms(Image.fromarray((image).astype(np.uint8))) for image in images]\n",
    "    transformed_images = torch.stack(transformed_images).to(device)\n",
    "    \n",
    "    # Predict the output for each image using the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(transformed_images)\n",
    "    \n",
    "    # Convert predictions to readable format\n",
    "    _, predicted_indices = torch.max(outputs, 1)\n",
    "    predicted_answers = [prediction_map[idx.item()] for idx in predicted_indices]\n",
    "    \n",
    "    # Calculate marks\n",
    "    marks = []\n",
    "    for pred, correct in zip(predicted_answers, correct_answers):\n",
    "        if pred == correct:\n",
    "            marks.append(1)\n",
    "        else:\n",
    "            marks.append(0)\n",
    "    \n",
    "    return marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be0ef05c-ee34-438b-98ad-c2d8088d8057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grade_Sheets(directory, model, correct_answers, qno=-1):\n",
    "    current_time = str(time.time())[:10]\n",
    "    with open(f\"Graded_Sheets_vit_{current_time}.csv\", \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"ID\", \"Predicted Marks\"])\n",
    "        \n",
    "        files = [file for file in os.listdir(directory) if file.endswith(('jpg', 'jpeg', 'png'))]\n",
    "        \n",
    "        for file in tqdm(files, desc=\"Grading Sheets\"):\n",
    "            img = cv2.imread(f\"{directory}/{file}\")\n",
    "            images = save_tf_answers(img, qno)\n",
    "            \n",
    "            if images is None:\n",
    "                continue  # Skip if no images were extracted\n",
    "            \n",
    "            marks = evaluate_answers(model, images, correct_answers, device)\n",
    "            \n",
    "            writer.writerow([file, np.sum(marks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a19d6d-84bf-4fdd-aa0b-fd69378f7fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Segregator\n",
    "#Change the file paths then run\n",
    "\n",
    "#Only Run if you need to Segregate Images based on Mapping\n",
    "#Create a Copy of Original Dataset before Running\n",
    "\n",
    "map_file = \"Phase-1 Evaluation Dataset/img_model_answer_mapping.csv\"\n",
    "img_directory = \"Phase-1 Evaluation Dataset/test\"\n",
    "with open(map_file, \"r\") as f:\n",
    "    reader = csv.reader(f); \n",
    "    skip = 0\n",
    "    for row in reader:\n",
    "        if(skip == 0):\n",
    "            skip = 1\n",
    "            continue\n",
    "        mapping = row[1]\n",
    "        image_name = row[0]\n",
    "        if not os.path.exists(mapping):\n",
    "            os.makedirs(mapping)\n",
    "        try:\n",
    "            shutil.move(f'{img_directory}/{image_name}', f'{mapping}/{image_name}')\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62ef79-1b54-4289-b3f2-80058ea485ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USAGE => Add the directory path to the sheets to be graded in directory variable, load model, load correct answers.\n",
    "\n",
    "directory = \"C:/Users/tusha/Desktop/NCVP/Data Samples/Sample_Data\"\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_save_path = \"best_models/best_model_vit.pth\"\n",
    "\n",
    "# Load the model architecture\n",
    "pretrained_vit = torchvision.models.vit_b_16(weights=None).to(device)  # Initialize with no weights\n",
    "pretrained_vit.heads = nn.Linear(in_features=768, out_features=3).to(device)  # Assuming 3 classes: True, False, Empty\n",
    "\n",
    "# Load the saved state dictionary into the model\n",
    "pretrained_vit.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "pretrained_vit.eval()\n",
    "\n",
    "#correct_answers = ['True', 'True', 'False', 'False', 'True', 'False', 'True', 'False', 'False', 'True']\n",
    "correct_answers = ['False', 'False', 'False', 'False', 'False', 'False', 'True', 'True', 'True', 'True']\n",
    "\n",
    "\n",
    "s = time.time()\n",
    "Grade_Sheets(directory, pretrained_vit, correct_answers)\n",
    "print(\"FINISHED:\", time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e9c475-234c-4fae-8765-bdfc671c0f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ï»¿img_name', 'pred_marks'], ['x9v67l6.jpg', ''], ['ewA8Rpn.jpg', ''], ['E6MwJ00.jpg', ''], ['9tuGAkX.jpg', ''], ['r53EbYv.jpg', ''], ['smkLrZa.jpg', ''], ['IRpxdDf.jpg', ''], ['hBD1FRE.jpg', ''], ['EXLa4p7.jpg', ''], ['uCpvJcc.jpg', ''], ['Ul9u6l6.jpg', ''], ['u2GZM4K.jpg', ''], ['D7klNpd.jpg', ''], ['yF4wPq5.jpg', ''], ['r9ByOWm.jpg', ''], ['52pqQSe.jpg', ''], ['Q2a6ahU.jpg', ''], ['BLK52Gc.jpg', ''], ['k0xTfJi.jpg', ''], ['msX3bBM.jpg', ''], ['nG4XW3E.jpg', ''], ['rtCMIC1.jpg', ''], ['WxtTFL6.jpg', ''], ['iw06r3Q.jpg', ''], ['PXamf6c.jpg', ''], ['RZH24s7.jpg', ''], ['favEvzP.jpg', ''], ['I3rHIGa.jpg', ''], ['LCB41h0.jpg', ''], ['T2EiQ3J.jpg', ''], ['uWMcs2Y.jpg', ''], ['56jXNyb.jpg', ''], ['6EoSuEJ.jpg', ''], ['pG15tPy.jpg', ''], ['OEOMwNz.jpg', ''], ['GCKySAb.jpg', ''], ['KikF8Hg.jpg', ''], ['g9OnxRJ.jpg', ''], ['6jHuOGj.jpg', ''], ['hr0SaFm.jpg', ''], ['t4fbUW1.jpg', ''], ['LRccyJJ.jpg', ''], ['fSgibgb.jpg', ''], ['sB9gIJP.jpg', ''], ['XHbvbhu.jpg', ''], ['k0R3DoI.jpg', ''], ['k3MGv5p.jpg', ''], ['5vQyXpN.jpg', ''], ['leDjQxO.jpg', ''], ['VOWRKeG.jpg', ''], ['1KUsNqb.jpg', ''], ['Zcai4vg.jpg', ''], ['k3fXpaB.jpg', ''], ['TphRpXN.jpg', ''], ['WqsQ2oM.jpg', ''], ['y1LnCHF.jpg', ''], ['naF0DTz.jpg', ''], ['fSoFduO.jpg', ''], ['tA3XsPA.jpg', ''], ['o6iFate.jpg', ''], ['Ao4IYZg.jpg', ''], ['Tybelpt.jpg', ''], ['dcKPZ70.jpg', ''], ['tRSUcnu.jpg', ''], ['il7ZzYK.jpg', ''], ['0MCLnne.jpg', ''], ['BwGdMO9.jpg', ''], ['94eVJfM.jpg', ''], ['YaewHUB.jpg', ''], ['dDKJWPG.jpg', ''], ['nV9zHTn.jpg', ''], ['fWen73r.jpg', ''], ['keUAEPk.jpg', ''], ['SHj76OQ.jpg', ''], ['xhc4R2G.jpg', ''], ['fxCtAQD.jpg', ''], ['PJeMxbg.jpg', ''], ['Vlo8tqw.jpg', ''], ['QHgIPCx.jpg', ''], ['NzBinsy.jpg', ''], ['cRogGRp.jpg', ''], ['yc12lqc.jpg', ''], ['n5LMW0T.jpg', ''], ['f6396vC.jpg', ''], ['8r86TYY.jpg', ''], ['IOj3f0x.jpg', ''], ['vrEo0y1.jpg', ''], ['L5rBGZ5.jpg', ''], ['diLM5gw.jpg', ''], ['jbJWS9A.jpg', ''], ['iz8f2EL.jpg', ''], ['VdH6dUQ.jpg', ''], ['pKLNQz5.jpg', ''], ['UeKwymv.jpg', ''], ['TXVeZeI.jpg', ''], ['sJcae3x.jpg', ''], ['s1XljD0.jpg', ''], ['LUYBpyQ.jpg', ''], ['Ef8ACCI.jpg', ''], ['7iL00J4.jpg', ''], ['xKeed9J.jpg', ''], ['bFD9eUD.jpg', ''], ['FMctx8O.jpg', ''], ['qNdhAQG.jpg', ''], ['bUvk9iA.jpg', ''], ['GRBnj1Z.jpg', ''], ['SMm9p1N.jpg', ''], ['6FPOAn4.jpg', ''], ['6xcmfsB.jpg', ''], ['alybfPY.jpg', ''], ['9q4RhnA.jpg', ''], ['7c7a0By.jpg', ''], ['seedZky.jpg', ''], ['GUALkq5.jpg', ''], ['N1HDgWz.jpg', ''], ['8uEnJiI.jpg', ''], ['s5fq6IA.jpg', ''], ['e38fphp.jpg', ''], ['j6uC3Xk.jpg', ''], ['6nLvfDA.jpg', ''], ['XYvZQ69.jpg', ''], ['jzBnw4J.jpg', ''], ['6tXsNC9.jpg', ''], ['KB26N1r.jpg', ''], ['Gn7hJNd.jpg', ''], ['zxomqZY.jpg', ''], ['7pahTUB.jpg', ''], ['JyjneLe.jpg', ''], ['DrHXuVC.jpg', ''], ['AZ76rSV.jpg', ''], ['SQ3PfSs.jpg', ''], ['eGngzyy.jpg', ''], ['LAB7L4d.jpg', ''], ['TQUHeNf.jpg', ''], ['dmZCR9Y.jpg', ''], ['rxCG3WE.jpg', ''], ['SxxUauX.jpg', ''], ['OqVkVCv.jpg', ''], ['NGhWj87.jpg', ''], ['8F8YMZl.jpg', ''], ['KKfbb39.jpg', ''], ['ZvHkGNT.jpg', ''], ['WJstHO0.jpg', ''], ['cScH1M6.jpg', ''], ['CLBs5ko.jpg', ''], ['UAPlfB2.jpg', ''], ['B4XCYz9.jpg', ''], ['EIHSAUE.jpg', ''], ['sVRUXRv.jpg', ''], ['H6JMOwY.jpg', ''], ['Qet6ZdJ.jpg', ''], ['nWCK5mU.jpg', ''], ['FNjcH1n.jpg', ''], ['BniP88N.jpg', ''], ['baS4IPn.jpg', ''], ['vrpQEKp.jpg', ''], ['h8CIV67.jpg', ''], ['Qi8cQd9.jpg', ''], ['Jqj9QLY.jpg', ''], ['lXzz6uS.jpg', ''], ['96QZdd8.jpg', ''], ['dKh1074.jpg', ''], ['DlrYDgV.jpg', ''], ['T04C5Cf.jpg', ''], ['cWwqME1.jpg', ''], ['sKJHopD.jpg', ''], ['xsXKhSL.jpg', ''], ['MV5KDC8.jpg', ''], ['KGv7TpN.jpg', ''], ['YqjoUp3.jpg', ''], ['4o6dYrK.jpg', ''], ['9ho2npk.jpg', ''], ['x8FnUkW.jpg', ''], ['OAg9Tcu.jpg', ''], ['wN4cbxp.jpg', ''], ['atMTlVH.jpg', ''], ['6ZEaAgP.jpg', ''], ['0OdLk7m.jpg', ''], ['gbeOzSl.jpg', ''], ['UpUB4NP.jpg', ''], ['d0CumBh.jpg', ''], ['jMBzTSY.jpg', ''], ['K4M2DDt.jpg', ''], ['MvHSRmI.jpg', ''], ['FikUEoA.jpg', ''], ['15KUC2C.jpg', ''], ['IF69nYD.jpg', ''], ['QjnYgjU.jpg', ''], ['A2sNCY3.jpg', ''], ['OKJ3j3G.jpg', ''], ['rBUuCSx.jpg', ''], ['F0nOhUP.jpg', ''], ['WacNh4T.jpg', ''], ['89atndp.jpg', ''], ['BJMdF88.jpg', ''], ['Rk1G1aS.jpg', ''], ['4eC8euy.jpg', ''], ['zQshA2F.jpg', ''], ['ZGzhVNg.jpg', ''], ['3G7htqD.jpg', ''], ['v4aJrqY.jpg', ''], ['y6Vf5sD.jpg', ''], ['UXsG00l.jpg', ''], ['HIZNGdx.jpg', ''], ['HOtiavT.jpg', ''], ['Qr2F5vt.jpg', ''], ['hJTSb28.jpg', ''], ['uwONgIj.jpg', ''], ['u6uDFnY.jpg', ''], ['lvPI3dz.jpg', ''], ['vpI8WEb.jpg', ''], ['mMcX0kT.jpg', ''], ['kK8CqVE.jpg', ''], ['dmBFpeL.jpg', ''], ['tpPFzmO.jpg', ''], ['ZGGigCm.jpg', ''], ['oYYOzj0.jpg', ''], ['S4Gjogj.jpg', ''], ['kc3HJAc.jpg', ''], ['bO9N14J.jpg', ''], ['2sjzRpB.jpg', ''], ['hOqd6O1.jpg', ''], ['0uMtPz0.jpg', ''], ['WbvDqtc.jpg', ''], ['1NFTcys.jpg', ''], ['6f36g6m.jpg', ''], ['mCkySBG.jpg', ''], ['eW2yoSH.jpg', ''], ['rzQDZm4.jpg', ''], ['bd3p317.jpg', ''], ['4us8p1f.jpg', ''], ['Hj9MaiP.jpg', ''], ['dYAaz7m.jpg', ''], ['qKVBUWs.jpg', ''], ['VrcsNov.jpg', ''], ['bOMQ443.jpg', ''], ['E0RhGxf.jpg', ''], ['jioK374.jpg', ''], ['uJgHSki.jpg', ''], ['5pOfNJj.jpg', ''], ['hSIB9dp.jpg', ''], ['vhKiEc5.jpg', ''], ['PJF97Sn.jpg', ''], ['SpbJje9.jpg', ''], ['qDeau8F.jpg', ''], ['9jJTcYP.jpg', ''], ['IZoP6L9.jpg', ''], ['DpJMbdM.jpg', ''], ['kGfwhg1.jpg', ''], ['hTdvXQF.jpg', ''], ['vljoMvg.jpg', ''], ['J4KSh3L.jpg', ''], ['q084olr.jpg', ''], ['LmfCbHP.jpg', ''], ['xE2j1uA.jpg', ''], ['406Rype.jpg', ''], ['UnyTYcI.jpg', ''], ['DiAuBgf.jpg', ''], ['XZfYPZf.jpg', ''], ['DpgnoTP.jpg', ''], ['hsrMdD1.jpg', ''], ['pzjmQaX.jpg', ''], ['QboFh7Q.jpg', ''], ['ZHdcDRf.jpg', ''], ['m0uDWq4.jpg', ''], ['DCqErqb.jpg', ''], ['x6TAizQ.jpg', ''], ['g2XWJ8f.jpg', ''], ['WG85Ru8.jpg', ''], ['2xCuXpB.jpg', ''], ['yArHNVc.jpg', ''], ['f5UXaA3.jpg', ''], ['KYwE0DO.jpg', ''], ['WZ5A722.jpg', ''], ['H9hqtAY.jpg', ''], ['o8Eg109.jpg', ''], ['0rmWKaj.jpg', ''], ['AEvXq0w.jpg', ''], ['pDpbHYg.jpg', ''], ['rYEPaeR.jpg', ''], ['MLNMK7L.jpg', ''], ['DT4N2Zg.jpg', ''], ['nD8jfSQ.jpg', ''], ['uhFFYJ4.jpg', ''], ['HGxZ4n9.jpg', ''], ['yfnPUlS.jpg', ''], ['1BDUOhL.jpg', ''], ['gMDq8yp.jpg', ''], ['EB96Q7Y.jpg', ''], ['Sm6e1Td.jpg', ''], ['GidbMC1.jpg', ''], ['JR5NBIN.jpg', ''], ['0c7xEno.jpg', ''], ['PAaDQxm.jpg', ''], ['UmqXxrS.jpg', ''], ['BUtmjUM.jpg', ''], ['gKxPK1Y.jpg', ''], ['3zxEEBC.jpg', ''], ['F0L3AOw.jpg', ''], ['mrijc85.jpg', ''], ['qXZqYLa.jpg', ''], ['WmsdhW5.jpg', ''], ['yFqaV83.jpg', ''], ['fNB1Xh6.jpg', ''], ['DyEbp6j.jpg', ''], ['tDvfNiE.jpg', ''], ['8e9QLg4.jpg', ''], ['YAvWe7x.jpg', ''], ['qmwIFuq.jpg', ''], ['kSgH2u5.jpg', ''], ['v10kqqM.jpg', ''], ['Kx9Dpvo.jpg', ''], ['JknFlEx.jpg', ''], ['xVlxPxC.jpg', ''], ['vblP2gM.jpg', ''], ['Icxu8bH.jpg', ''], ['DMStlYW.jpg', ''], ['y50hEHK.jpg', ''], ['NNgkxyl.jpg', ''], ['7T7pRQW.jpg', ''], ['AbOkl8A.jpg', ''], ['VMvseht.jpg', ''], ['k2F7UH9.jpg', ''], ['kLPP4io.jpg', ''], ['YvqixMk.jpg', ''], ['RDvyz0H.jpg', ''], ['246j0f6.jpg', ''], ['Q9W8wOw.jpg', ''], ['ofbF5fL.jpg', ''], ['XZZpu5U.jpg', ''], ['OasYZ7w.jpg', ''], ['DFGByuP.jpg', ''], ['ESaXykv.jpg', ''], ['jlxLpcG.jpg', ''], ['YAyfJTA.jpg', ''], ['FVofCFc.jpg', ''], ['icWtiVC.jpg', ''], ['bAgEOfS.jpg', ''], ['5nwXIEF.jpg', ''], ['CutQ325.jpg', ''], ['yyY2D8i.jpg', ''], ['KAyvprp.jpg', ''], ['nQw20fw.jpg', ''], ['NzodNAi.jpg', ''], ['neGZfyt.jpg', ''], ['q2ejgty.jpg', ''], ['uKXbpyN.jpg', ''], ['VxY3oie.jpg', ''], ['gKmfNLx.jpg', ''], ['oyXPXol.jpg', ''], ['1zHXQVK.jpg', ''], ['VW40e4h.jpg', ''], ['MgghiL8.jpg', ''], ['SGX6mEJ.jpg', ''], ['RFcUFz0.jpg', ''], ['cbIcLP0.jpg', ''], ['WcYuBgk.jpg', ''], ['kJqpZlJ.jpg', ''], ['rjFS7o6.jpg', ''], ['qwUhUnX.jpg', ''], ['plsg9LG.jpg', ''], ['RN7zNhk.jpg', ''], ['zaZoS31.jpg', ''], ['1PPvSt1.jpg', ''], ['feQ7tcB.jpg', ''], ['CsJgfN3.jpg', ''], ['3pGCYEU.jpg', ''], ['hkpSQ2K.jpg', ''], ['ucH9S9s.jpg', ''], ['7I0zVgw.jpg', ''], ['mlxhGQo.jpg', ''], ['jsuJUBM.jpg', ''], ['f6kyRqj.jpg', ''], ['MbaIt3p.jpg', ''], ['R2MhuVp.jpg', ''], ['Jz2iZTo.jpg', ''], ['uaLdeF8.jpg', ''], ['HS8kvmW.jpg', ''], ['xiBmbZu.jpg', ''], ['GoB1jLf.jpg', ''], ['8M5CU9m.jpg', ''], ['mWBX4hq.jpg', ''], ['A4qd5JR.jpg', ''], ['bztNZnR.jpg', ''], ['BlQwjrY.jpg', ''], ['rIRR2QT.jpg', ''], ['U1tXBng.jpg', ''], ['8m1YEXP.jpg', ''], ['Jg6DDR7.jpg', ''], ['RZzR3WP.jpg', ''], ['0CtvlvW.jpg', ''], ['Z2YvRlp.jpg', ''], ['5NGPXWn.jpg', ''], ['ZcOeygj.jpg', ''], ['EPA6x5l.jpg', ''], ['FpAdggD.jpg', ''], ['ebHOerd.jpg', ''], ['CVgnnPz.jpg', ''], ['lgTFx2j.jpg', ''], ['JX0es3Z.jpg', ''], ['Ar4iTZu.jpg', ''], ['1f5kc6O.jpg', ''], ['H2iPb1j.jpg', ''], ['xL6QQZg.jpg', ''], ['F436xrf.jpg', ''], ['gOCVU3H.jpg', ''], ['jx1zqEB.jpg', ''], ['Nqj6Ukg.jpg', ''], ['RRYfaw8.jpg', ''], ['DYcwFZ2.jpg', ''], ['OsPw2qc.jpg', ''], ['LPYDGGc.jpg', ''], ['dzWtTiV.jpg', ''], ['od6O51t.jpg', ''], ['7vXHnR1.jpg', ''], ['RRxEwCR.jpg', ''], ['eMa8BlA.jpg', ''], ['PWkOVq9.jpg', ''], ['R4Lqvlx.jpg', ''], ['7iS1YLO.jpg', ''], ['NUQPQV8.jpg', ''], ['JcwfXfG.jpg', ''], ['SxOFztL.jpg', ''], ['CVx5tZW.jpg', ''], ['jVAcbJd.jpg', ''], ['eJT0NAj.jpg', ''], ['kaXEAip.jpg', ''], ['DtoSTqh.jpg', ''], ['Onp7BQB.jpg', ''], ['9X9qVWN.jpg', ''], ['5VUV5Ds.jpg', ''], ['CrwqCnM.jpg', ''], ['SqzzLX5.jpg', ''], ['IHbBRG1.jpg', ''], ['Lj8xMTS.jpg', ''], ['J5RlmQv.jpg', ''], ['eDELdBV.jpg', ''], ['UmIo7nf.jpg', ''], ['PYdhI8v.jpg', ''], ['RNxITzv.jpg', ''], ['lTliwxI.jpg', ''], ['SUT4AWW.jpg', ''], ['jiooheu.jpg', ''], ['LSxnasq.jpg', ''], ['1CCExTK.jpg', ''], ['5GvROcS.jpg', ''], ['104uBJZ.jpg', ''], ['d698jqy.jpg', ''], ['gPUwdE9.jpg', ''], ['IbR3JQ2.jpg', ''], ['InCQsuH.jpg', ''], ['gygqDOa.jpg', ''], ['ZiJMj3P.jpg', ''], ['0Ld34zC.jpg', ''], ['VcAzqW1.jpg', ''], ['lLhLJNY.jpg', ''], ['fq5o2TP.jpg', ''], ['gWKDGZp.jpg', ''], ['Itmbytc.jpg', ''], ['GiTl4gv.jpg', ''], ['AuWeWTd.jpg', ''], ['04t0i6U.jpg', ''], ['SLoEgZp.jpg', ''], ['36XFKDU.jpg', ''], ['W9e6qNn.jpg', ''], ['40B8D9P.jpg', ''], ['WcmRS3m.jpg', ''], ['vxiTFZD.jpg', ''], ['SWEGOOj.jpg', ''], ['z9iMChP.jpg', ''], ['cODChJY.jpg', ''], ['GgtAhBF.jpg', ''], ['6bqo0C9.jpg', ''], ['STcovYo.jpg', ''], ['jzWkUcH.jpg', ''], ['l1ZVgCG.jpg', ''], ['pgxC4RR.jpg', ''], ['xicjOgf.jpg', ''], ['cUCYouh.jpg', ''], ['nx4Jtjd.jpg', ''], ['WJnOlzC.jpg', ''], ['55RvBa9.jpg', ''], ['SF26PyJ.jpg', ''], ['1gwlmOe.jpg', ''], ['gyP6GmY.jpg', ''], ['0qZVJKm.jpg', ''], ['uGqNWz5.jpg', ''], ['5ZXQiqK.jpg', ''], ['wNpuM8I.jpg', ''], ['fW3Q3I0.jpg', ''], ['qz31CIs.jpg', ''], ['nrdsLDa.jpg', ''], ['fj6yfEh.jpg', ''], ['hhJrQUf.jpg', ''], ['hEADtQh.jpg', ''], ['MKo064b.jpg', ''], ['ypdRsuD.jpg', ''], ['tjERJXl.jpg', ''], ['thbXo3M.jpg', ''], ['qOjvI4Q.jpg', ''], ['IUmBbJR.jpg', ''], ['TLzmbPh.jpg', ''], ['jwVRl8o.jpg', ''], ['IEH3YjW.jpg', ''], ['lbg7D6C.jpg', ''], ['yvobPIk.jpg', ''], ['faXTONV.jpg', ''], ['D2hIAB7.jpg', ''], ['qJ7zBpR.jpg', ''], ['SsSbA8u.jpg', ''], ['vMtPuyM.jpg', ''], ['xaxBugs.jpg', ''], ['GdDku30.jpg', ''], ['O0KTNBq.jpg', ''], ['A2bBrU9.jpg', ''], ['RCTcSK5.jpg', ''], ['dOhV2kI.jpg', ''], ['My1dMYr.jpg', ''], ['2PvIZDE.jpg', ''], ['GMgHHm1.jpg', ''], ['CCqulRg.jpg', ''], ['XXfy8uN.jpg', ''], ['pBOLe58.jpg', ''], ['JmeCIC1.jpg', ''], ['YJ8QXIH.jpg', ''], ['ZU7kvGx.jpg', ''], ['3kYHjN0.jpg', ''], ['gtyqlcL.jpg', ''], ['GyyJzOi.jpg', ''], ['CgQmkHz.jpg', ''], ['lyr0YBB.jpg', ''], ['zciEYbt.jpg', ''], ['5Abx9M2.jpg', ''], ['J6SsjFs.jpg', ''], ['roxXaVD.jpg', ''], ['TAJCbig.jpg', ''], ['VyHTNQ9.jpg', ''], ['obx0nEW.jpg', ''], ['v5r2evS.jpg', ''], ['XiPBY60.jpg', ''], ['ly91BaO.jpg', ''], ['WjrciTI.jpg', ''], ['a72tRvR.jpg', ''], ['LNZv5Pn.jpg', ''], ['AwF0CBa.jpg', ''], ['3pwsTyE.jpg', ''], ['LQah8ff.jpg', ''], ['sAoxOtx.jpg', ''], ['sOHz97N.jpg', ''], ['SevT653.jpg', ''], ['gjQ3l7z.jpg', ''], ['pi57kK6.jpg', ''], ['tc0TwSp.jpg', ''], ['H6A3t08.jpg', ''], ['gdtcR42.jpg', ''], ['YUtXx1Q.jpg', ''], ['IqSlvss.jpg', ''], ['tYiDdZY.jpg', ''], ['rZQ0RuV.jpg', ''], ['gOTMKLB.jpg', ''], ['epimQv0.jpg', ''], ['9FgCGu3.jpg', ''], ['0lnF9tq.jpg', ''], ['DSxCXr6.jpg', ''], ['AUFftAQ.jpg', ''], ['lqdSQBD.jpg', ''], ['Kk3EIE8.jpg', ''], ['GUJBXzs.jpg', ''], ['rZbH3th.jpg', ''], ['2bdo5ud.jpg', ''], ['AoWLqhH.jpg', ''], ['lx19RYA.jpg', ''], ['57xTE5U.jpg', ''], ['qlwikIg.jpg', ''], ['F4DRxwk.jpg', ''], ['XtmUIuV.jpg', ''], ['I6Y9leA.jpg', ''], ['VJFlqhC.jpg', ''], ['Zfq18VD.jpg', ''], ['EPXRcep.jpg', ''], ['NIDRNKM.jpg', ''], ['S9amPJh.jpg', ''], ['YAy4x2y.jpg', ''], ['wCaaOdq.jpg', ''], ['wGegiaZ.jpg', ''], ['17Eh4M5.jpg', ''], ['w1cmMVA.jpg', ''], ['gaFls3o.jpg', ''], ['yuRHqjH.jpg', ''], ['sPGI0Yj.jpg', ''], ['7UgFm9q.jpg', ''], ['8wUWOwd.jpg', ''], ['niEMuqt.jpg', ''], ['VT1eUse.jpg', ''], ['qFKyFdJ.jpg', ''], ['nVDIV7v.jpg', ''], ['b2UruIc.jpg', ''], ['2EufWcq.jpg', ''], ['ROdYDt2.jpg', ''], ['IbBere6.jpg', ''], ['AhnOq2U.jpg', ''], ['rijC15L.jpg', ''], ['y2wzyA1.jpg', ''], ['zWXFXYW.jpg', ''], ['FpQD5VW.jpg', ''], ['fZ2tBIx.jpg', ''], ['ICIXFCp.jpg', ''], ['u20CbaY.jpg', ''], ['n1jxrs3.jpg', ''], ['mGHkXo0.jpg', ''], ['xPcfWPI.jpg', ''], ['bvW2cMc.jpg', ''], ['MNx2JmJ.jpg', ''], ['u9Wer6S.jpg', ''], ['q8iJyk0.jpg', ''], ['Bk5vzlP.jpg', ''], ['hhP1kex.jpg', ''], ['jLVlBi4.jpg', ''], ['89Qr0VM.jpg', ''], ['CG1NIoo.jpg', ''], ['yRPD0Dn.jpg', ''], ['MBJiE0X.jpg', ''], ['54jROSP.jpg', ''], ['apa52fV.jpg', ''], ['y2z8DRH.jpg', ''], ['KctCRld.jpg', ''], ['nhDmSKc.jpg', ''], ['MmuQQou.jpg', ''], ['zHa0aYH.jpg', ''], ['vHWNFJ2.jpg', ''], ['VQI5gRv.jpg', ''], ['uSpnyHB.jpg', ''], ['O63hzUh.jpg', ''], ['R0rvJ4W.jpg', ''], ['D6dDvU3.jpg', ''], ['Sb9xEDW.jpg', ''], ['yo3KVbK.jpg', ''], ['vT46Zg1.jpg', ''], ['NDKzZ1k.jpg', ''], ['G1CZP6M.jpg', ''], ['plR6CUU.jpg', ''], ['frSrwVi.jpg', ''], ['PtQ8lwm.jpg', ''], ['oTtfso4.jpg', ''], ['bOOb4M8.jpg', '']]\n"
     ]
    }
   ],
   "source": [
    "#Untested \n",
    "\n",
    "submission_dict = []\n",
    "submission_list = []\n",
    "with open(\"Phase-1 Evaluation Dataset/submission.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    skip = 0\n",
    "    \n",
    "    for row in reader:\n",
    "        if(skip == 0):\n",
    "            skip = 1\n",
    "            continue\n",
    "        submission_dict[row[0]] = 0\n",
    "        submission_list.append(row[0])\n",
    "print(submission_dict)\n",
    "with open(\"prediction.csv\", 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    skip = 0\n",
    "    \n",
    "    for row in reader:\n",
    "        if(skip == 0):\n",
    "            skip = 1\n",
    "            continue\n",
    "        submission_dict[row[0]] = row[1]\n",
    "\n",
    "if not os.path.exists(\"output):\n",
    "    os.makedirs(\"output\")\n",
    "with open(\"output/submission.csv\", 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for i in submission_list:\n",
    "        writer.writerow([i, submission_dict[i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c903998-8bc2-4a80-b6d1-37469c461e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
